version: "3.8"
services:
  # gateway:
  #   build: .
  #   ports:
  #     - "8080:8080"
  #   depends_on:
  #     - db
  #     - news_service
  #   environment:
  #     - DATABASE_URL=postgresql://user:password@db:5432/gateway?schema=public

  # db:
  #   image: postgres:13
  #   environment:
  #     - POSTGRES_USER=user
  #     - POSTGRES_PASSWORD=password
  #     - POSTGRES_DB=gateway
  #   volumes:
  #     - postgres_data:/var/lib/postgresql/data
  # zookeeper:
  #   image: confluentinc/cp-zookeeper:latest
  #   environment:
  #     ZOOKEEPER_CLIENT_PORT: 2181
  #     ZOOKEEPER_TICK_TIME: 2000
  #   networks:
  #     - my-custom-network
  # kafka:
  #   image: confluentinc/cp-kafka:latest
  #   depends_on:
  #     - zookeeper
  #   ports:
  #     - "9092:9092"
  #   expose:
  #     - 9092
  #   environment:
  #     ZOOKEEPER_SASL_ENABLED: "false"
  #     KAFKA_BROKER_ID: 1
  #     KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
  #     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
  #     KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  #   networks:
  #     - my-custom-network

  # on working
  # news_service:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile
  #   environment:
  #     MONGO_URI: mongodb://mongodb:27017/
  #     KAFKA_BROKER: kafka:9092
  #   depends_on:
  #     - kafka-0
  #     - kafka-1
  #     - kafka-2
  #     - mongodb
  #   networks:
  #     - my-custom-network
  broker:
    image: confluentinc/cp-kafka:latest
    hostname: broker
    container_name: broker
    ports:
      - "9092:9092" # Expose Kafka broker port
      - "9101:9101" # JMX port for monitoring
    environment:
      # Unique Node ID
      KAFKA_NODE_ID: 1

      # Define security protocol for each listener
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"

      # Advertised listeners for broker (internal network) and external access (localhost)
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092"

      # Replication and state log configuration for Kafka topics
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1

      # Reduces the initial rebalance delay to make group rebalancing faster
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0

      # JMX settings for monitoring Kafka
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost

      # Specify the roles for the node (broker + controller)
      KAFKA_PROCESS_ROLES: "broker,controller"

      # Define controller quorum voters (KRaft mode)
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@broker:29093"

      # Define listeners (PLAINTEXT for the broker, CONTROLLER for the KRaft controller)
      KAFKA_LISTENERS: "PLAINTEXT://broker:29092,CONTROLLER://broker:29093,PLAINTEXT_HOST://0.0.0.0:9092"

      # Inter-broker communication is via PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"

      # The controller will listen on the CONTROLLER protocol
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"

      # Directory to store log data
      KAFKA_LOG_DIRS: "/tmp/kraft-combined-logs"

      # KRaft mode requires a unique CLUSTER_ID
      # Use "bin/kafka-storage.sh random-uuid" to generate this value.
      CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk" # Replace with a generated UUID

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    ports:
      - "9999:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: broker:29092

  schema-registry:
    image: confluentinc/cp-schema-registry:latest
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      - broker
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "broker:29092"
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081

  mongodb:
    image: mongo:latest
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
    networks:
      - my-custom-network

  kafka-exporter:
    image: danielqsj/kafka-exporter:latest
    container_name: kafka-exporter
    depends_on:
      - broker
      - schema-registry
      - kafka-ui
    command:
      - --kafka.server=broker:29092
      - --web.listen-address=:9308
    ports:
      - "9308:9308"

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    depends_on:
      - kafka-exporter
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3333:3000"
    depends_on:
      - kafka-exporter
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana-storage:/var/lib/grafana
  # kafka-ui:
  #   container_name: kafka-ui
  #   image: provectuslabs/kafka-ui:latest
  #   ports:
  #     - 9090:8080
  #   environment:
  #     DYNAMIC_CONFIG_ENABLED: true
  #   depends_on:
  #     - kafka-0
  #     - kafka-1
  #     - kafka-2
  #   networks:
  #     - kafka-net
  #   volumes:
  #     - ./kafka-ui/config.yml:/etc/kafkaui/dynamic_config.yaml

  # kafka-setup:
  #   image: bitnami/kafka:latest
  #   depends_on:
  #     - kafka-0
  #     - kafka-1
  #     - kafka-2
  #   command: >
  #     bash -c "
  #       echo Waiting for Kafka to be ready...
  #       sleep 30
  #       echo Creating Kafka topics...
  #       kafka-topics.sh --create --if-not-exists --bootstrap-server kafka-0:9092 --partitions 2 --replication-factor 3 --topic scraped-news
  #       echo Kafka topics created.
  #     "
  #   networks:
  #     - kafka-net
volumes:
  mongodb_data:
  volume1:
  grafana-storage:

networks:
  my-custom-network:
    external: true
  kafka-net:
    driver: bridge
